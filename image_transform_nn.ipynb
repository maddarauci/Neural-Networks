{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_transform_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpVKQ09S0clfBBqPQqKl6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maddarauci/Neural-Networks/blob/main/image_transform_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZMmOtdcT6OI",
        "outputId": "c41cbeb8-7059-4470-cf75-ec126af63bf2"
      },
      "source": [
        "pip install keras scipy numpy pillow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "P2ham9rtT0kq",
        "outputId": "8b4d709d-faa0-4916-9dd9-0c993b20a276"
      },
      "source": [
        "import PIL.Image\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import save_img\n",
        "from PIL import Image\n",
        "import argparse\n",
        "\n",
        "# preprocessing image to make it compatible with the vgg19 model\n",
        "def preprocess_image(image_path, resized_width, resized_height):\n",
        "  img = load_img(image_path, target_size=(resized_width, resized_height))\n",
        "  img = img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = vgg19.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "# function to convert a tensor to an image\n",
        "def deprocess_image(x, resized_width, resized_height):\n",
        "  x = x.reshape((resized_width, resized_height, 3))\n",
        "\n",
        "  # remove zero center by mean pixel. necessary when working with vgg model \n",
        "  z[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "\n",
        "  # format bgr to rgb \n",
        "  x = x[:, :, ::-1]\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x \n",
        "\n",
        "# the gram matrix of an image tensor is the inner product between the vectorized feature map in a layer.\n",
        "# it is used to compute the style lo, minimizing the mean squared distance between the feature correlation map of the style imag\n",
        "# and the input image \n",
        "\n",
        "def gram_matrix(x):\n",
        "  features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "  gram = K.dot(features, K.transpose(features))\n",
        "  return gram \n",
        "\n",
        "# the style_loss_per_layer represents the loss between the style of the style reference image and the generated image.\n",
        "# it depends of the gram matrices of features maps from the style reference image and from the generated image.\n",
        "\n",
        "def style_loss_per_layer(style, combination, resized_width, resized_height):\n",
        "  S = gram_matrix(style)\n",
        "  C = gram_matrix(combination)\n",
        "  channels = 3\n",
        "  size = resized_width * resized_height\n",
        "  return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "# the total_style_loss represents the total loss between the style of the style reference image and generated image, \n",
        "# taking into account all the layers considered for the style transfer, related to the style reference image.\n",
        "\n",
        "def total_style_loss(feature_layers, output_dict, resized_width, resized_height, style_weight):\n",
        "  loss = K.variable(0.)\n",
        "  for layer_name in feature_layer:\n",
        "    layer_features = output_dict[layer_name]\n",
        "    style_reference_features = layers_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl - style_loss_per_layer(style_reference_features, combination_features, resized_width, resized_height)\n",
        "    loss += (style_weight / len(featue_layers)) * sl \n",
        "  return loss \n",
        "\n",
        "# the content loss maintains the features of the content image in the generated image.\n",
        "def content_loss(layers_features):\n",
        "  base_image_features = layer_features[0, :, :, :]\n",
        "  combination_features = layers_features[2, :, :, :]\n",
        "  return K.sum(K.square(combination_features - base_image_features))\n",
        "\n",
        "# the total variation loss maintains the generated image localy coherent,\n",
        "# smoothing the pixel variatants among the neighbour pixels.\n",
        "def total_variation(x, resized_width, resized_height):\n",
        "  a = K.square(x[:, :resized_width - 1, :resized_height - 1, :] - x[:, 1: :resized_height - 1, :]) \n",
        "  b = K.square(x[:, :resized_width - 1, :resized_height - 1, :] - x[:, :resized_height - 1, 1, :])\n",
        "  return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "def total_loss(outputs_dict, content_weight, resized_width, resized_height, style_weight, total_variation_weight, combination_image):\n",
        "   loss = K.variable(0.)\n",
        "\n",
        "   # contribution of content_loss\n",
        "   features_layers_content = outputs_dict['block5_conv2']\n",
        "   loss += content_weight * content_loss(features_layers_content)\n",
        "\n",
        "   # contribution of style_loss\n",
        "   feature_layer_style = ['block1_conv1', 'block2_conv1',\n",
        "                          'block3_conv1', 'block4_conv1',\n",
        "                          'block5_conv1']\n",
        "   loss += total_style_loss(features_layers_style, outputs_dict, resized_width, resized_height, style_weight) * style_weight\n",
        "\n",
        "   # contribution of variation_loss\n",
        "   loss += total_variation_weight * total_variation_loss(combination_image, resized_width, resized_height)\n",
        "   return loss \n",
        "\n",
        "# evaluate the loss and gradients respect to the generated image. it is called in the evaluator, necessary to \n",
        "# to compute gradients and the loss as two different functions (limitation of the L-BFGS algorithmn) without\n",
        "# excessive losses in performance \n",
        "\n",
        "def eval_loss_and_grads(x, resized_width, resized_height, f_outputs):\n",
        "  x = x.reshape((1, resized_width, resized_height, 3))\n",
        "  outs = f_outputs([x])\n",
        "  loss_value = outs[0]\n",
        "  if len(outs[1:]) == 1:\n",
        "    grad_values = outs[1].flatten().astype('float64')\n",
        "  else:\n",
        "    grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "  return loss_value, grad_values\n",
        "  \n",
        "# save generated pictures\n",
        "def save(filename, generated):\n",
        "  save_img(filename, Image.fromarray(generated))\n",
        "\n",
        "# evaluator returns the loss and the gradient in two separate functions, but the calculation of the two variables\n",
        "# are dependent. this reduces the computation time, since otherwise it would be calculated separately.\n",
        "\n",
        "class Evaluator(object):\n",
        "  def __init__(self, resized_width, resized_height, f_outputs):\n",
        "    self.loss_value = None\n",
        "    self.grad_values = None \n",
        "    self.resized_width = resized_width\n",
        "    self.resized_height = resized_height\n",
        "    self.f_outputs = f_outputs \n",
        "\n",
        "  def loss(self, x):\n",
        "    assert self.loss_value is None \n",
        "    loss_value, grad_values = eval_loss_and_grads(x, self.resized_width, self.resized_height, self.f_outputs)\n",
        "    self.loss_value = loss_value \n",
        "    self.grad_values = grad_values\n",
        "    return self.loss_value \n",
        "  def grad(self, x):\n",
        "    assert self.loss_value is not None \n",
        "    grad_values = np.copy(self.grad_values)\n",
        "    self.loss_value = None\n",
        "    self.grad_values = None\n",
        "    return grad_values\n",
        "\n",
        "def run(args):\n",
        "  # variable declaration\n",
        "  base_image_path = f\"reference_images/base_image/{args.base_image}\"\n",
        "  style_reference_image_path = \"reference_images/style_image/{args.style_image}\"\n",
        "  iterations = args.iterations \n",
        "\n",
        "  # weights to compare the final loss\n",
        "  totaal_variation_weight = 1\n",
        "  style_weight = 2\n",
        "  contetn_weight = 5\n",
        "\n",
        "  # dimensions of the generated picture.\n",
        "  width, height = load_imag(base_image_path).size\n",
        "  resized_width = 400\n",
        "  resized_height = int(width * resized_width / height)\n",
        "\n",
        "  # get tensor representation of the image\n",
        "  base_image = K.variable(preprocess_image(base_image_path, resized_width, resized_height))\n",
        "  style_reference_image = K.variable(preprocess_image(style_reference_image_path, resized_width, resized_height))\n",
        "\n",
        "  # place holder for generated images\n",
        "  combination_image = K.placeholder((1, resized_width, resized_height, 3))\n",
        "\n",
        "  # combine the 3 images into a single keras tensor \n",
        "  input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
        "\n",
        "  # build the vgg19 network with our 3 images as input \n",
        "  # the model is loaded with pre-trained ImageNet weights\n",
        "  model = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "  # get the outputs of each key layer, through unique names.\n",
        "  outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "  loss = total_loss(outputs_dict, content_weight, resized_width, resized_height, style_weight, total_variation_weight, combination_image)\n",
        "\n",
        "\n",
        "  # get the gradient of the generated image.\n",
        "  grads = K.gradients(loss, combination_image)\n",
        "  outputs = [loss]\n",
        "  outputs += grads\n",
        "\n",
        "  f_outputs = K.function([combination_image], outputs)\n",
        "    \n",
        "  evaluator = Evaluator(resized_width, resized_height, f_outputs)\n",
        "\n",
        "  x = preprocess_image(base_image_path, resized_width, resized_height)\n",
        "    \n",
        "  # The oprimizer is fmin_l_bfgs\n",
        "  for i in range(iterations):\n",
        "      print('Iteration: ', i)\n",
        "      x, min_val, info = fmin_l_bfgs_b(evaluator.loss,\n",
        "                                        x.flatten(),\n",
        "                                        fprime=evaluator.grads,\n",
        "                                        maxfun=25)\n",
        "  \n",
        "      print('Current loss value:', min_val)\n",
        "  \n",
        "      # Save current generated image\n",
        "      img = deprocess_image(x.copy(), resized_width, resized_height)\n",
        "      fname = 'results/' + np.str(i) + '.png'\n",
        "      save(fname, img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\tdone\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set options to activate or deactivate the game view, and its speed\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--base_image\", type=str, default=\"jumping_me.jpg\")\n",
        "    parser.add_argument(\"--style_image\", type=str, default=\"starry_night.jpg\")\n",
        "    parser.add_argument(\"--iterations\", type=int, default=20)\n",
        "    args = parser.parse_args()\n",
        "    run(args)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--base_image BASE_IMAGE]\n",
            "                             [--style_image STYLE_IMAGE]\n",
            "                             [--iterations ITERATIONS]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-d77b66cf-8e7d-465c-9287-83742dbfc3bc.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}